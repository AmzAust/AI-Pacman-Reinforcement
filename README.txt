For my implementation, the strategy hasn't changed too much from
the past assignments. It involves getting Q values or computing
them, adding them to lists and returning the maximum so that we
can take the best action. However sometimes we needed to use
probability to get actions so we use random.choice or flipCoin.
For mdp's Q values were computed by using states, actions,
and rewards. For valueIterationAgents.py Q values were obtained
by getting transition states and probabilities using rewards, 
states, actions and discounts.
